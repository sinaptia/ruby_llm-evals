_fixture:
  model_class: RubyLLM::Evals::PromptExecution

one:
  sample: one
  run: one
  eval_type: exact
  expected_output: car
  variables: {}
  input: 1500
  output: 20
  message: car
  passed: true
  active_job_id: test-job-1

two:
  sample: two
  run: two
  eval_type: contains
  expected_output: "Rails"
  variables: { "text": "Ruby on Rails is a web framework written in Ruby" }
  input: 2000
  output: 150
  message: "Rails is a popular web framework."
  passed: true
  active_job_id: test-job-2

three:
  sample: three
  run: three
  eval_type: regex
  expected_output: "(positive|negative|neutral)"
  variables: { "text": "This product is amazing! I love it." }
  input: 1800
  output: 10
  message: positive
  passed: true
  active_job_id: test-job-3

four:
  sample: four
  run: three
  eval_type: human
  expected_output: null
  variables: { "text": "The weather is nice today." }
  input: 1600
  output: 8
  message: neutral
  passed: null
  active_job_id: test-job-4

five:
  sample: five
  run: three
  eval_type: llm_judge
  expected_output: "The output should correctly answer the question asked"
  judge_model: "gemini-2.0-flash-001"
  judge_provider: "gemini"
  variables: { "question": "What is the capital of France?" }
  input: 1200
  output: 15
  judge_input: 800
  judge_output: 50
  message: "Paris"
  judge_message: { "passed": true, "reasoning": "Correctly identifies Paris as the capital of France" }
  passed: true
  active_job_id: test-job-5
