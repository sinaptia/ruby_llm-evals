_fixture:
  model_class: RubyLLM::Evals::Sample

one:
  prompt: one
  eval_type: exact
  expected_output: car
  variables: {}

two:
  prompt: two
  eval_type: contains
  expected_output: "Rails"
  variables: { "text": "Ruby on Rails is a web framework written in Ruby" }

two_b:
  prompt: two
  eval_type: contains
  expected_output: "framework"
  variables: { "text": "Django is a Python web framework for building web applications" }

three:
  prompt: three
  eval_type: regex
  expected_output: "(positive|negative|neutral)"
  variables: { "text": "This product is amazing! I love it." }

four:
  prompt: three
  eval_type: human_judge
  expected_output: null
  variables: { "text": "The weather is nice today." }

five:
  prompt: three
  eval_type: llm_judge
  expected_output: "The output should correctly answer the question asked"
  judge_model: "gemini-2.0-flash-001"
  judge_provider: "gemini"
  variables: { "text": "What is the capital of France?" }
